{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T16:57:07.878120Z",
     "start_time": "2021-07-09T16:57:07.852834Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T16:57:08.360207Z",
     "start_time": "2021-07-09T16:57:08.345992Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T16:57:10.486408Z",
     "start_time": "2021-07-09T16:57:08.714801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA environment device set to 0\n"
     ]
    }
   ],
   "source": [
    "from ds_toolkit.general_utils.gpu_utils import addGPU\n",
    "addGPU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T16:57:27.392711Z",
     "start_time": "2021-07-09T16:57:10.490601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] seed set 1\n",
      "[INFO] Cuda Avaliable :  True\n",
      "[INFO] device :  cuda\n",
      "[INFO] Loading Data\n",
      "Files already downloaded and verified\n",
      "[INFO] train dataset of size 50000 loaded...\n",
      "Files already downloaded and verified\n",
      "[INFO] test dataset of size 10000 loaded...\n"
     ]
    }
   ],
   "source": [
    "from main import Trainer\n",
    "from models import (\n",
    "    resnet_v1,\n",
    "    resnet_v2_6ch_ending,\n",
    "    resnet_v3_GAP_v1_k3_p1,\n",
    "    resnet_v3_GAP_v2_k1_p1,\n",
    "    resnet_v3_GAP_v3_k1_p0,\n",
    ")\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "except ModuleNotFoundError as e:\n",
    "    print(e, 'Logging module failed to import !')\n",
    "\n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T12:07:52.193995Z",
     "start_time": "2021-07-09T11:55:17.033966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 28, 28]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 28, 28]             128\n",
      "            Conv2d-3           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 28, 28]             128\n",
      "            Conv2d-5           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 28, 28]             128\n",
      "        BasicBlock-7           [-1, 64, 28, 28]               0\n",
      "            Conv2d-8           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 28, 28]             128\n",
      "           Conv2d-10           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 28, 28]             128\n",
      "       BasicBlock-12           [-1, 64, 28, 28]               0\n",
      "           Conv2d-13          [-1, 128, 14, 14]          73,728\n",
      "      BatchNorm2d-14          [-1, 128, 14, 14]             256\n",
      "           Conv2d-15          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-16          [-1, 128, 14, 14]             256\n",
      "           Conv2d-17          [-1, 128, 14, 14]           8,192\n",
      "      BatchNorm2d-18          [-1, 128, 14, 14]             256\n",
      "       BasicBlock-19          [-1, 128, 14, 14]               0\n",
      "           Conv2d-20          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-21          [-1, 128, 14, 14]             256\n",
      "           Conv2d-22          [-1, 128, 14, 14]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 14, 14]             256\n",
      "       BasicBlock-24          [-1, 128, 14, 14]               0\n",
      "           Conv2d-25            [-1, 256, 7, 7]         294,912\n",
      "      BatchNorm2d-26            [-1, 256, 7, 7]             512\n",
      "           Conv2d-27            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-28            [-1, 256, 7, 7]             512\n",
      "           Conv2d-29            [-1, 256, 7, 7]          32,768\n",
      "      BatchNorm2d-30            [-1, 256, 7, 7]             512\n",
      "       BasicBlock-31            [-1, 256, 7, 7]               0\n",
      "           Conv2d-32            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-33            [-1, 256, 7, 7]             512\n",
      "           Conv2d-34            [-1, 256, 7, 7]         589,824\n",
      "      BatchNorm2d-35            [-1, 256, 7, 7]             512\n",
      "       BasicBlock-36            [-1, 256, 7, 7]               0\n",
      "           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-41            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-43            [-1, 512, 4, 4]               0\n",
      "           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n",
      "       BasicBlock-48            [-1, 512, 4, 4]               0\n",
      "           Linear-49                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,173,962\n",
      "Trainable params: 11,173,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 8.79\n",
      "Params size (MB): 42.63\n",
      "Estimated Total Size (MB): 51.42\n",
      "----------------------------------------------------------------\n",
      "TEST         Loss:0.0182         Acc:9.90         [990 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maskmuhsin\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.33 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.11<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">R18_normal</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/askmuhsin/resnet_18_cifar\" target=\"_blank\">https://wandb.ai/askmuhsin/resnet_18_cifar</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/askmuhsin/resnet_18_cifar/runs/2i8j7k3t\" target=\"_blank\">https://wandb.ai/askmuhsin/resnet_18_cifar/runs/2i8j7k3t</a><br/>\n",
       "                Run data is saved locally in <code>/data/omnibox1/muhsin/OOB_experiments/eva/eva_training_flow/tests/wandb/run-20210709_195527-2i8j7k3t</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Begin training for 23 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:0 Loss:1.1827 Batch:390 Acc:47.13: 100%|██████████| 391/391 [00:28<00:00, 13.96it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0090         Acc:59.71         [5971 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:1 Loss:0.8231 Batch:390 Acc:66.36: 100%|██████████| 391/391 [00:27<00:00, 13.99it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0066         Acc:72.03         [7203 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:2 Loss:0.6541 Batch:390 Acc:73.64: 100%|██████████| 391/391 [00:28<00:00, 13.56it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0049         Acc:78.56         [7856 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:3 Loss:0.6436 Batch:390 Acc:77.77: 100%|██████████| 391/391 [00:28<00:00, 13.53it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0048         Acc:79.37         [7937 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:4 Loss:0.6665 Batch:390 Acc:80.56: 100%|██████████| 391/391 [00:29<00:00, 13.24it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0060         Acc:74.38         [7438 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:5 Loss:0.4719 Batch:390 Acc:82.24: 100%|██████████| 391/391 [00:29<00:00, 13.40it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0041         Acc:82.13         [8213 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:6 Loss:0.453 Batch:390 Acc:84.06: 100%|██████████| 391/391 [00:29<00:00, 13.43it/s] \n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0039         Acc:83.29         [8329 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:7 Loss:0.3084 Batch:390 Acc:85.22: 100%|██████████| 391/391 [00:29<00:00, 13.40it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0040         Acc:82.72         [8272 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:8 Loss:0.2902 Batch:390 Acc:86.48: 100%|██████████| 391/391 [00:29<00:00, 13.42it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0038         Acc:83.93         [8393 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:9 Loss:0.5165 Batch:390 Acc:87.28: 100%|██████████| 391/391 [00:30<00:00, 12.91it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0035         Acc:85.36         [8536 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:10 Loss:0.2706 Batch:390 Acc:87.93: 100%|██████████| 391/391 [00:29<00:00, 13.42it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0033         Acc:86.25         [8625 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:11 Loss:0.3877 Batch:390 Acc:89.05: 100%|██████████| 391/391 [00:32<00:00, 12.16it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0037         Acc:84.93         [8493 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:12 Loss:0.3283 Batch:390 Acc:89.27: 100%|██████████| 391/391 [00:30<00:00, 12.63it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0034         Acc:85.92         [8592 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:13 Loss:0.1954 Batch:390 Acc:90.09: 100%|██████████| 391/391 [00:29<00:00, 13.15it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0032         Acc:87.15         [8715 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:14 Loss:0.211 Batch:390 Acc:90.65: 100%|██████████| 391/391 [00:29<00:00, 13.47it/s] \n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0033         Acc:86.88         [8688 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:15 Loss:0.1753 Batch:390 Acc:91.06: 100%|██████████| 391/391 [00:29<00:00, 13.17it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0031         Acc:87.55         [8755 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:16 Loss:0.2734 Batch:390 Acc:91.41: 100%|██████████| 391/391 [00:29<00:00, 13.25it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0033         Acc:86.95         [8695 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:17 Loss:0.2151 Batch:390 Acc:91.93: 100%|██████████| 391/391 [00:29<00:00, 13.11it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0034         Acc:86.62         [8662 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:18 Loss:0.2277 Batch:390 Acc:92.38: 100%|██████████| 391/391 [00:29<00:00, 13.45it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0031         Acc:87.77         [8777 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:19 Loss:0.3022 Batch:390 Acc:92.53: 100%|██████████| 391/391 [00:28<00:00, 13.53it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0034         Acc:86.37         [8637 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:20 Loss:0.241 Batch:390 Acc:92.68: 100%|██████████| 391/391 [00:29<00:00, 13.42it/s] \n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0035         Acc:86.72         [8672 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:21 Loss:0.2884 Batch:390 Acc:92.97: 100%|██████████| 391/391 [00:28<00:00, 13.56it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0031         Acc:87.96         [8796 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:22 Loss:0.157 Batch:390 Acc:93.26: 100%|██████████| 391/391 [00:29<00:00, 13.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0031         Acc:87.68         [8768 / 10000]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 29403<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/data/omnibox1/muhsin/OOB_experiments/eva/eva_training_flow/tests/wandb/run-20210709_195527-2i8j7k3t/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/data/omnibox1/muhsin/OOB_experiments/eva/eva_training_flow/tests/wandb/run-20210709_195527-2i8j7k3t/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_acc</td><td>93.65403</td></tr><tr><td>test_acc</td><td>87.68</td></tr><tr><td>train_loss</td><td>0.19809</td></tr><tr><td>test_loss</td><td>0.00312</td></tr><tr><td>lr</td><td>0.00968</td></tr><tr><td>_step</td><td>22</td></tr><tr><td>_runtime</td><td>739</td></tr><tr><td>_timestamp</td><td>1625832466</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>train_acc</td><td>▁▄▅▆▆▇▇▇▇▇▇▇███████████</td></tr><tr><td>test_acc</td><td>▁▄▆▆▅▇▇▇▇▇█▇▇██████████</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_loss</td><td>█▅▃▃▄▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>██████▇▇▇▇▆▆▆▅▅▅▄▄▃▃▂▂▁</td></tr><tr><td>_step</td><td>▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">R18_normal</strong>: <a href=\"https://wandb.ai/askmuhsin/resnet_18_cifar/runs/2i8j7k3t\" target=\"_blank\">https://wandb.ai/askmuhsin/resnet_18_cifar/runs/2i8j7k3t</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(resnet_v1.ResNet18())\n",
    "\n",
    "## before training\n",
    "trainer.evaluate_model()\n",
    "\n",
    "run = wandb.init(\n",
    "    project='resnet_18_cifar', \n",
    "    entity='askmuhsin', \n",
    "    reinit=True,\n",
    "    name=\"R18_normal\",\n",
    "    notes=\"This is the basic resnet\"\n",
    ")\n",
    "trainer.train_model(epochs, wandb=run)\n",
    "run.finish()\n",
    "\n",
    "del trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet with 6X6 channel size ending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T17:00:36.565175Z",
     "start_time": "2021-07-09T17:00:31.240913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 28, 28]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 28, 28]             128\n",
      "            Conv2d-3           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 28, 28]             128\n",
      "            Conv2d-5           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 28, 28]             128\n",
      "        BasicBlock-7           [-1, 64, 28, 28]               0\n",
      "            Conv2d-8           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 28, 28]             128\n",
      "           Conv2d-10           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 28, 28]             128\n",
      "       BasicBlock-12           [-1, 64, 28, 28]               0\n",
      "           Conv2d-13          [-1, 128, 15, 15]          73,728\n",
      "      BatchNorm2d-14          [-1, 128, 15, 15]             256\n",
      "           Conv2d-15          [-1, 128, 15, 15]         147,456\n",
      "      BatchNorm2d-16          [-1, 128, 15, 15]             256\n",
      "           Conv2d-17          [-1, 128, 15, 15]           8,192\n",
      "      BatchNorm2d-18          [-1, 128, 15, 15]             256\n",
      "       BasicBlock-19          [-1, 128, 15, 15]               0\n",
      "           Conv2d-20          [-1, 128, 15, 15]         147,456\n",
      "      BatchNorm2d-21          [-1, 128, 15, 15]             256\n",
      "           Conv2d-22          [-1, 128, 15, 15]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 15, 15]             256\n",
      "       BasicBlock-24          [-1, 128, 15, 15]               0\n",
      "           Conv2d-25            [-1, 256, 9, 9]         294,912\n",
      "      BatchNorm2d-26            [-1, 256, 9, 9]             512\n",
      "           Conv2d-27            [-1, 256, 9, 9]         589,824\n",
      "      BatchNorm2d-28            [-1, 256, 9, 9]             512\n",
      "           Conv2d-29            [-1, 256, 9, 9]          32,768\n",
      "      BatchNorm2d-30            [-1, 256, 9, 9]             512\n",
      "       BasicBlock-31            [-1, 256, 9, 9]               0\n",
      "           Conv2d-32            [-1, 256, 9, 9]         589,824\n",
      "      BatchNorm2d-33            [-1, 256, 9, 9]             512\n",
      "           Conv2d-34            [-1, 256, 9, 9]         589,824\n",
      "      BatchNorm2d-35            [-1, 256, 9, 9]             512\n",
      "       BasicBlock-36            [-1, 256, 9, 9]               0\n",
      "           Conv2d-37            [-1, 512, 6, 6]       1,179,648\n",
      "      BatchNorm2d-38            [-1, 512, 6, 6]           1,024\n",
      "           Conv2d-39            [-1, 512, 6, 6]       2,359,296\n",
      "      BatchNorm2d-40            [-1, 512, 6, 6]           1,024\n",
      "           Conv2d-41            [-1, 512, 6, 6]         131,072\n",
      "      BatchNorm2d-42            [-1, 512, 6, 6]           1,024\n",
      "       BasicBlock-43            [-1, 512, 6, 6]               0\n",
      "           Conv2d-44            [-1, 512, 6, 6]       2,359,296\n",
      "      BatchNorm2d-45            [-1, 512, 6, 6]           1,024\n",
      "           Conv2d-46            [-1, 512, 6, 6]       2,359,296\n",
      "      BatchNorm2d-47            [-1, 512, 6, 6]           1,024\n",
      "       BasicBlock-48            [-1, 512, 6, 6]               0\n",
      "           Linear-49                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,173,962\n",
      "Trainable params: 11,173,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 10.82\n",
      "Params size (MB): 42.63\n",
      "Estimated Total Size (MB): 53.45\n",
      "----------------------------------------------------------------\n",
      "TEST         Loss:0.0182         Acc:10.00         [1000 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to query for notebook name, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maskmuhsin\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: <ipython-input-7-ea53c69472e9> 12 <module>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ea53c69472e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mreinit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"R18_6_channel_more_epochs\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mnotes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"with 6X6 channels for gradcam\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/safe/envs/dask_env/lib/python3.6/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"interrupted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0merror_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/safe/envs/dask_env/lib/python3.6/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m             \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/safe/envs/dask_env/lib/python3.6/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             ret = backend.interface.communicate_check_version(\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0mcurrent_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m             )\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/safe/envs/dask_env/lib/python3.6/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mcommunicate_check_version\u001b[0;34m(self, current_version)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0mcheck_version\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_communicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m             \u001b[0;31m# Note: timeouts handled by callers: wandb_init.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/safe/envs/dask_env/lib/python3.6/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36m_communicate\u001b[0;34m(self, rec, timeout, local)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_router\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_router\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_and_receive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcommunicate_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manonymous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/safe/envs/dask_env/lib/python3.6/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mis_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object_ready\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_set\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/safe/envs/3.6.12/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/safe/envs/3.6.12/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(resnet_v2_6ch_ending.ResNet18())\n",
    "\n",
    "## before training\n",
    "## best out of all\n",
    "trainer.evaluate_model()\n",
    "\n",
    "run = wandb.init(\n",
    "    project='resnet_18_cifar', \n",
    "    entity='askmuhsin', \n",
    "    reinit=True,\n",
    "    name=\"R18_6_channel_more_epochs\",\n",
    "    notes=\"with 6X6 channels for gradcam\"\n",
    ")\n",
    "trainer.train_model(epochs, wandb=run)\n",
    "run.finish()\n",
    "\n",
    "del trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet with GAP (k3, p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-09T11:55:20.705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 28, 28]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 28, 28]             128\n",
      "            Conv2d-3           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 28, 28]             128\n",
      "            Conv2d-5           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 28, 28]             128\n",
      "        BasicBlock-7           [-1, 64, 28, 28]               0\n",
      "            Conv2d-8           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 28, 28]             128\n",
      "           Conv2d-10           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 28, 28]             128\n",
      "       BasicBlock-12           [-1, 64, 28, 28]               0\n",
      "           Conv2d-13          [-1, 128, 15, 15]          73,728\n",
      "      BatchNorm2d-14          [-1, 128, 15, 15]             256\n",
      "           Conv2d-15          [-1, 128, 15, 15]         147,456\n",
      "      BatchNorm2d-16          [-1, 128, 15, 15]             256\n",
      "           Conv2d-17          [-1, 128, 15, 15]           8,192\n",
      "      BatchNorm2d-18          [-1, 128, 15, 15]             256\n",
      "       BasicBlock-19          [-1, 128, 15, 15]               0\n",
      "           Conv2d-20          [-1, 128, 15, 15]         147,456\n",
      "      BatchNorm2d-21          [-1, 128, 15, 15]             256\n",
      "           Conv2d-22          [-1, 128, 15, 15]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 15, 15]             256\n",
      "       BasicBlock-24          [-1, 128, 15, 15]               0\n",
      "           Conv2d-25            [-1, 256, 9, 9]         294,912\n",
      "      BatchNorm2d-26            [-1, 256, 9, 9]             512\n",
      "           Conv2d-27            [-1, 256, 9, 9]         589,824\n",
      "      BatchNorm2d-28            [-1, 256, 9, 9]             512\n",
      "           Conv2d-29            [-1, 256, 9, 9]          32,768\n",
      "      BatchNorm2d-30            [-1, 256, 9, 9]             512\n",
      "       BasicBlock-31            [-1, 256, 9, 9]               0\n",
      "           Conv2d-32            [-1, 256, 9, 9]         589,824\n",
      "      BatchNorm2d-33            [-1, 256, 9, 9]             512\n",
      "           Conv2d-34            [-1, 256, 9, 9]         589,824\n",
      "      BatchNorm2d-35            [-1, 256, 9, 9]             512\n",
      "       BasicBlock-36            [-1, 256, 9, 9]               0\n",
      "           Conv2d-37            [-1, 512, 6, 6]       1,179,648\n",
      "      BatchNorm2d-38            [-1, 512, 6, 6]           1,024\n",
      "           Conv2d-39            [-1, 512, 6, 6]       2,359,296\n",
      "      BatchNorm2d-40            [-1, 512, 6, 6]           1,024\n",
      "           Conv2d-41            [-1, 512, 6, 6]         131,072\n",
      "      BatchNorm2d-42            [-1, 512, 6, 6]           1,024\n",
      "       BasicBlock-43            [-1, 512, 6, 6]               0\n",
      "           Conv2d-44            [-1, 512, 6, 6]       2,359,296\n",
      "      BatchNorm2d-45            [-1, 512, 6, 6]           1,024\n",
      "           Conv2d-46            [-1, 512, 6, 6]       2,359,296\n",
      "      BatchNorm2d-47            [-1, 512, 6, 6]           1,024\n",
      "       BasicBlock-48            [-1, 512, 6, 6]               0\n",
      "           Conv2d-49             [-1, 10, 6, 6]          46,080\n",
      "        AvgPool2d-50             [-1, 10, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 11,214,912\n",
      "Trainable params: 11,214,912\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 10.82\n",
      "Params size (MB): 42.78\n",
      "Estimated Total Size (MB): 53.61\n",
      "----------------------------------------------------------------\n",
      "TEST         Loss:0.0182         Acc:10.03         [1003 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.33 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.11<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">R18_GAP_k3_p1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/askmuhsin/resnet_18_cifar\" target=\"_blank\">https://wandb.ai/askmuhsin/resnet_18_cifar</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/askmuhsin/resnet_18_cifar/runs/1f9devgx\" target=\"_blank\">https://wandb.ai/askmuhsin/resnet_18_cifar/runs/1f9devgx</a><br/>\n",
       "                Run data is saved locally in <code>/data/omnibox1/muhsin/OOB_experiments/eva/eva_training_flow/tests/wandb/run-20210709_202348-1f9devgx</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Begin training for 23 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:0 Loss:1.2365 Batch:390 Acc:40.13: 100%|██████████| 391/391 [00:40<00:00,  9.70it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0093         Acc:57.19         [5719 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:1 Loss:0.9111 Batch:390 Acc:58.74: 100%|██████████| 391/391 [00:39<00:00,  9.96it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0073         Acc:67.74         [6774 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:2 Loss:0.9132 Batch:390 Acc:67.84: 100%|██████████| 391/391 [00:39<00:00,  9.98it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0067         Acc:69.89         [6989 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:3 Loss:0.8109 Batch:80 Acc:72.57:  20%|██        | 80/391 [00:08<00:29, 10.41it/s]"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(resnet_v3_GAP_v1_k3_p1.ResNet18())\n",
    "\n",
    "## before training\n",
    "trainer.evaluate_model()\n",
    "\n",
    "run = wandb.init(\n",
    "    project='resnet_18_cifar', \n",
    "    entity='askmuhsin', \n",
    "    reinit=True,\n",
    "    name=\"R18_GAP_k3_p1\",\n",
    "    notes=\"with GAP\"\n",
    ")\n",
    "trainer.train_model(epochs, wandb=run)\n",
    "run.finish()\n",
    "\n",
    "del trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet with GAP (k1, p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T16:59:32.249371Z",
     "start_time": "2021-07-09T16:59:31.908197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 28, 28]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 28, 28]             128\n",
      "            Conv2d-3           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 28, 28]             128\n",
      "            Conv2d-5           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 28, 28]             128\n",
      "        BasicBlock-7           [-1, 64, 28, 28]               0\n",
      "            Conv2d-8           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 28, 28]             128\n",
      "           Conv2d-10           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 28, 28]             128\n",
      "       BasicBlock-12           [-1, 64, 28, 28]               0\n",
      "           Conv2d-13          [-1, 128, 15, 15]          73,728\n",
      "      BatchNorm2d-14          [-1, 128, 15, 15]             256\n",
      "           Conv2d-15          [-1, 128, 15, 15]         147,456\n",
      "      BatchNorm2d-16          [-1, 128, 15, 15]             256\n",
      "           Conv2d-17          [-1, 128, 15, 15]           8,192\n",
      "      BatchNorm2d-18          [-1, 128, 15, 15]             256\n",
      "       BasicBlock-19          [-1, 128, 15, 15]               0\n",
      "           Conv2d-20          [-1, 128, 15, 15]         147,456\n",
      "      BatchNorm2d-21          [-1, 128, 15, 15]             256\n",
      "           Conv2d-22          [-1, 128, 15, 15]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 15, 15]             256\n",
      "       BasicBlock-24          [-1, 128, 15, 15]               0\n",
      "           Conv2d-25            [-1, 256, 9, 9]         294,912\n",
      "      BatchNorm2d-26            [-1, 256, 9, 9]             512\n",
      "           Conv2d-27            [-1, 256, 9, 9]         589,824\n",
      "      BatchNorm2d-28            [-1, 256, 9, 9]             512\n",
      "           Conv2d-29            [-1, 256, 9, 9]          32,768\n",
      "      BatchNorm2d-30            [-1, 256, 9, 9]             512\n",
      "       BasicBlock-31            [-1, 256, 9, 9]               0\n",
      "           Conv2d-32            [-1, 256, 9, 9]         589,824\n",
      "      BatchNorm2d-33            [-1, 256, 9, 9]             512\n",
      "           Conv2d-34            [-1, 256, 9, 9]         589,824\n",
      "      BatchNorm2d-35            [-1, 256, 9, 9]             512\n",
      "       BasicBlock-36            [-1, 256, 9, 9]               0\n",
      "           Conv2d-37            [-1, 512, 6, 6]       1,179,648\n",
      "      BatchNorm2d-38            [-1, 512, 6, 6]           1,024\n",
      "           Conv2d-39            [-1, 512, 6, 6]       2,359,296\n",
      "      BatchNorm2d-40            [-1, 512, 6, 6]           1,024\n",
      "           Conv2d-41            [-1, 512, 6, 6]         131,072\n",
      "      BatchNorm2d-42            [-1, 512, 6, 6]           1,024\n",
      "       BasicBlock-43            [-1, 512, 6, 6]               0\n",
      "           Conv2d-44            [-1, 512, 6, 6]       2,359,296\n",
      "      BatchNorm2d-45            [-1, 512, 6, 6]           1,024\n",
      "           Conv2d-46            [-1, 512, 6, 6]       2,359,296\n",
      "      BatchNorm2d-47            [-1, 512, 6, 6]           1,024\n",
      "       BasicBlock-48            [-1, 512, 6, 6]               0\n",
      "           Conv2d-49             [-1, 10, 8, 8]           5,120\n",
      "        AvgPool2d-50             [-1, 10, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 11,173,952\n",
      "Trainable params: 11,173,952\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 10.82\n",
      "Params size (MB): 42.63\n",
      "Estimated Total Size (MB): 53.46\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(resnet_v3_GAP_v2_k1_p1.ResNet18())\n",
    "\n",
    "## before training\n",
    "trainer.evaluate_model()\n",
    "\n",
    "run = wandb.init(\n",
    "    project='resnet_18_cifar', \n",
    "    entity='askmuhsin', \n",
    "    reinit=True,\n",
    "    name=\"R18_GAP_k1_p1\",\n",
    "    notes=\"with GAP k1\"\n",
    ")\n",
    "trainer.train_model(epochs, wandb=run)\n",
    "run.finish()\n",
    "\n",
    "del trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet with GAP (k1, p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-09T13:11:31.273766Z",
     "start_time": "2021-07-09T12:55:36.359550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 28, 28]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 28, 28]             128\n",
      "            Conv2d-3           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 28, 28]             128\n",
      "            Conv2d-5           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 28, 28]             128\n",
      "        BasicBlock-7           [-1, 64, 28, 28]               0\n",
      "            Conv2d-8           [-1, 64, 28, 28]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 28, 28]             128\n",
      "           Conv2d-10           [-1, 64, 28, 28]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 28, 28]             128\n",
      "       BasicBlock-12           [-1, 64, 28, 28]               0\n",
      "           Conv2d-13          [-1, 128, 15, 15]          73,728\n",
      "      BatchNorm2d-14          [-1, 128, 15, 15]             256\n",
      "           Conv2d-15          [-1, 128, 15, 15]         147,456\n",
      "      BatchNorm2d-16          [-1, 128, 15, 15]             256\n",
      "           Conv2d-17          [-1, 128, 15, 15]           8,192\n",
      "      BatchNorm2d-18          [-1, 128, 15, 15]             256\n",
      "       BasicBlock-19          [-1, 128, 15, 15]               0\n",
      "           Conv2d-20          [-1, 128, 15, 15]         147,456\n",
      "      BatchNorm2d-21          [-1, 128, 15, 15]             256\n",
      "           Conv2d-22          [-1, 128, 15, 15]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 15, 15]             256\n",
      "       BasicBlock-24          [-1, 128, 15, 15]               0\n",
      "           Conv2d-25            [-1, 256, 9, 9]         294,912\n",
      "      BatchNorm2d-26            [-1, 256, 9, 9]             512\n",
      "           Conv2d-27            [-1, 256, 9, 9]         589,824\n",
      "      BatchNorm2d-28            [-1, 256, 9, 9]             512\n",
      "           Conv2d-29            [-1, 256, 9, 9]          32,768\n",
      "      BatchNorm2d-30            [-1, 256, 9, 9]             512\n",
      "       BasicBlock-31            [-1, 256, 9, 9]               0\n",
      "           Conv2d-32            [-1, 256, 9, 9]         589,824\n",
      "      BatchNorm2d-33            [-1, 256, 9, 9]             512\n",
      "           Conv2d-34            [-1, 256, 9, 9]         589,824\n",
      "      BatchNorm2d-35            [-1, 256, 9, 9]             512\n",
      "       BasicBlock-36            [-1, 256, 9, 9]               0\n",
      "           Conv2d-37            [-1, 512, 6, 6]       1,179,648\n",
      "      BatchNorm2d-38            [-1, 512, 6, 6]           1,024\n",
      "           Conv2d-39            [-1, 512, 6, 6]       2,359,296\n",
      "      BatchNorm2d-40            [-1, 512, 6, 6]           1,024\n",
      "           Conv2d-41            [-1, 512, 6, 6]         131,072\n",
      "      BatchNorm2d-42            [-1, 512, 6, 6]           1,024\n",
      "       BasicBlock-43            [-1, 512, 6, 6]               0\n",
      "           Conv2d-44            [-1, 512, 6, 6]       2,359,296\n",
      "      BatchNorm2d-45            [-1, 512, 6, 6]           1,024\n",
      "           Conv2d-46            [-1, 512, 6, 6]       2,359,296\n",
      "      BatchNorm2d-47            [-1, 512, 6, 6]           1,024\n",
      "       BasicBlock-48            [-1, 512, 6, 6]               0\n",
      "           Conv2d-49             [-1, 10, 6, 6]           5,120\n",
      "        AvgPool2d-50             [-1, 10, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 11,173,952\n",
      "Trainable params: 11,173,952\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 10.82\n",
      "Params size (MB): 42.63\n",
      "Estimated Total Size (MB): 53.45\n",
      "----------------------------------------------------------------\n",
      "TEST         Loss:0.0182         Acc:10.00         [1000 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.33 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.11<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">R18_GAP_k1_p0</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/askmuhsin/resnet_18_cifar\" target=\"_blank\">https://wandb.ai/askmuhsin/resnet_18_cifar</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/askmuhsin/resnet_18_cifar/runs/186qc9ew\" target=\"_blank\">https://wandb.ai/askmuhsin/resnet_18_cifar/runs/186qc9ew</a><br/>\n",
       "                Run data is saved locally in <code>/data/omnibox1/muhsin/OOB_experiments/eva/eva_training_flow/tests/wandb/run-20210709_205539-186qc9ew</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Begin training for 23 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:0 Loss:1.1568 Batch:390 Acc:46.88: 100%|██████████| 391/391 [00:37<00:00, 10.32it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0087         Acc:61.38         [6138 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:1 Loss:1.193 Batch:390 Acc:64.67: 100%|██████████| 391/391 [00:37<00:00, 10.36it/s] \n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0074         Acc:67.94         [6794 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:2 Loss:0.8144 Batch:390 Acc:72.31: 100%|██████████| 391/391 [00:38<00:00, 10.17it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0057         Acc:74.95         [7495 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:3 Loss:0.5439 Batch:390 Acc:76.18: 100%|██████████| 391/391 [00:38<00:00, 10.18it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0072         Acc:68.71         [6871 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:4 Loss:0.4658 Batch:390 Acc:78.70: 100%|██████████| 391/391 [00:38<00:00, 10.11it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0046         Acc:79.97         [7997 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:5 Loss:0.4314 Batch:390 Acc:81.39: 100%|██████████| 391/391 [00:37<00:00, 10.33it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0044         Acc:81.71         [8171 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:6 Loss:0.3461 Batch:390 Acc:82.76: 100%|██████████| 391/391 [00:38<00:00, 10.14it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0053         Acc:77.58         [7758 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:7 Loss:0.3451 Batch:43 Acc:84.87:  11%|█▏        | 44/391 [00:04<00:32, 10.71it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "TRAIN Epoch:8 Loss:0.3501 Batch:390 Acc:85.14: 100%|██████████| 391/391 [00:38<00:00, 10.26it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0037         Acc:84.15         [8415 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:9 Loss:0.3468 Batch:390 Acc:86.13: 100%|██████████| 391/391 [00:38<00:00, 10.18it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0040         Acc:82.95         [8295 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:10 Loss:0.4255 Batch:390 Acc:87.20: 100%|██████████| 391/391 [00:38<00:00, 10.28it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0042         Acc:82.09         [8209 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:11 Loss:0.1414 Batch:390 Acc:87.90: 100%|██████████| 391/391 [00:38<00:00, 10.17it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0043         Acc:82.32         [8232 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:12 Loss:0.2781 Batch:390 Acc:88.75: 100%|██████████| 391/391 [00:37<00:00, 10.30it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0038         Acc:84.48         [8448 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:13 Loss:0.3338 Batch:180 Acc:89.52:  46%|████▌     | 180/391 [00:17<00:20, 10.19it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "TRAIN Epoch:16 Loss:0.2818 Batch:390 Acc:90.84: 100%|██████████| 391/391 [00:38<00:00, 10.28it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0035         Acc:85.84         [8584 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:17 Loss:0.1633 Batch:390 Acc:91.35: 100%|██████████| 391/391 [00:39<00:00,  9.94it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0032         Acc:87.41         [8741 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:18 Loss:0.153 Batch:390 Acc:91.71: 100%|██████████| 391/391 [00:38<00:00, 10.26it/s] \n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0032         Acc:87.09         [8709 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:19 Loss:0.223 Batch:390 Acc:91.74: 100%|██████████| 391/391 [00:38<00:00, 10.26it/s] \n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0033         Acc:87.13         [8713 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:20 Loss:0.1915 Batch:390 Acc:92.14: 100%|██████████| 391/391 [00:38<00:00, 10.28it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST         Loss:0.0034         Acc:87.10         [8710 / 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN Epoch:21 Loss:0.2007 Batch:63 Acc:92.60:  16%|█▌        | 62/391 [00:06<00:30, 10.80it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(resnet_v3_GAP_v3_k1_p0.ResNet18())\n",
    "\n",
    "## before training\n",
    "trainer.evaluate_model()\n",
    "\n",
    "run = wandb.init(\n",
    "    project='resnet_18_cifar', \n",
    "    entity='askmuhsin', \n",
    "    reinit=True,\n",
    "    name=\"R18_GAP_k1_p0\",\n",
    "    notes=\"with GAP k1 p0\"\n",
    ")\n",
    "trainer.train_model(epochs, wandb=run)\n",
    "run.finish()\n",
    "\n",
    "del trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
